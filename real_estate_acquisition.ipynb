{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports, then load the data and inspect it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d9e52c0b272c347"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[('2e5d8815-4e59-4302-99c0-6fc9593a2eef',\n  'GATE_IN',\n  datetime.datetime(2023, 1, 31, 8, 18, 36, tzinfo=datetime.timezone.utc)),\n ('a8c60645-aef4-4b4e-aefb-65e242536c2f',\n  'GATE_IN',\n  datetime.datetime(2023, 1, 31, 8, 43, 41, tzinfo=datetime.timezone.utc)),\n ('0b99d382-ea52-4a1d-8e9e-218933c0d7b8',\n  'GATE_IN',\n  datetime.datetime(2023, 1, 31, 8, 43, 47, tzinfo=datetime.timezone.utc))]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from statistics import variance\n",
    "import unittest\n",
    "\n",
    "def load_all_data(file_path: str) -> List[Tuple[str, str, datetime]]:\n",
    "    \"\"\"Load all event data from a CSV file.\"\"\"\n",
    "    all_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip header\n",
    "        for line in csv_reader:\n",
    "            user_id, event_type, event_time = line\n",
    "            event_time = datetime.fromisoformat(event_time.replace(\"Z\", \"+00:00\"))\n",
    "            all_data.append((user_id, event_type.upper(), event_time))\n",
    "    return all_data\n",
    "\n",
    "data = load_all_data('datapao_homework_2023.csv')\n",
    "data[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:36:17.681515700Z",
     "start_time": "2023-10-07T16:36:17.638450900Z"
    }
   },
   "id": "d60a6f9f08e12181"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Calculate the amount of time and the number of days each person has spent in the office in February. Write results to a CSV, in the format (user_id, time, days, average_per_day, rank)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3eb46733438dc6"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/first.csv\n"
     ]
    }
   ],
   "source": [
    "def filter_and_sort_data(data_source: Union[str, List[Tuple[str, str, datetime]]]) -> List[Tuple[str, str, datetime]]:\n",
    "    \"\"\"Filter and sort event data for the month of February.\"\"\"\n",
    "    if isinstance(data_source, str):\n",
    "        all_data = load_all_data(data_source)\n",
    "        feb_data = [entry for entry in all_data if entry[2].month == 2]\n",
    "    else:\n",
    "        feb_data = [entry for entry in data_source if entry[2].month == 2]\n",
    "    feb_data.sort(key=lambda x: (x[0], x[2]))\n",
    "    return feb_data\n",
    "\n",
    "def calculate_user_metrics(feb_data: List[Tuple[str, str, datetime]]) -> Tuple[Dict[str, float], Dict[str, set]]:\n",
    "    \"\"\"Calculate metrics like time spent, unique days for each user based on the correct solution.\"\"\"\n",
    "    users = defaultdict(lambda: {'time': 0, 'days': set()})\n",
    "\n",
    "    for user_id, event_type, event_time in feb_data:\n",
    "        if event_type == 'GATE_IN':\n",
    "            users[user_id]['current_in'] = event_time\n",
    "        elif event_type == 'GATE_OUT' and 'current_in' in users[user_id]:\n",
    "            duration = (event_time - users[user_id]['current_in']).seconds / 3600  # Convert to hours\n",
    "            users[user_id]['time'] += duration\n",
    "            users[user_id]['days'].add(event_time.date())\n",
    "            del users[user_id]['current_in']  # Reset for next pair\n",
    "\n",
    "    # Transforming the data to align with the previous structure\n",
    "    user_time = {user: users[user]['time'] for user in users}\n",
    "    user_days = {user: users[user]['days'] for user in users}\n",
    "\n",
    "    return user_time, user_days\n",
    "\n",
    "def calculate_avg_time_and_rank(user_time: Dict[str, float], user_days: Dict[str, set]) -> Tuple[Dict[str, float], Dict[str, int]]:\n",
    "    \"\"\"Calculate average time and ordinal rank for each user.\"\"\"\n",
    "    user_avg_time = {user: user_time[user] / len(user_days[user]) for user in user_time}\n",
    "    sorted_users = sorted(user_avg_time.items(), key=lambda x: x[1], reverse=True)\n",
    "    user_rank = {user: rank + 1 for rank, (user, _) in enumerate(sorted_users)}\n",
    "    return user_avg_time, user_rank\n",
    "\n",
    "def write_to_csv(output_data: List[List[Union[str, int, float]]], header: List[str], file_path: str) -> None:\n",
    "    \"\"\"Write calculated metrics to a CSV file.\"\"\"\n",
    "    with open(file_path, 'w', newline='') as file:\n",
    "        csv_writer = csv.writer(file)\n",
    "        csv_writer.writerow(header)\n",
    "        csv_writer.writerows(output_data)\n",
    "\n",
    "def task_one_main(file_path: str, output_file_path: str) -> None:\n",
    "    \"\"\"Main function to execute Task 1: Calculate and write user metrics to a CSV.\"\"\"\n",
    "    feb_data = filter_and_sort_data(file_path)\n",
    "    user_time, user_days = calculate_user_metrics(feb_data)\n",
    "    user_avg_time, user_rank = calculate_avg_time_and_rank(user_time, user_days)\n",
    "\n",
    "    output_data = [[user, user_time[user], len(user_days[user]), user_avg_time[user], user_rank[user]] for user in user_time]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = 'output/'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Define the complete output file path\n",
    "    complete_output_file_path = os.path.join(output_directory, output_file_path)\n",
    "    print(complete_output_file_path)\n",
    "\n",
    "    # Write the data to a CSV file\n",
    "    write_to_csv(output_data, ['user_id', 'time', 'days', 'average_per_day', 'rank'], complete_output_file_path)\n",
    "\n",
    "\n",
    "### Some test driver code\n",
    "# # Recalculate user metrics using the corrected function\n",
    "# user_time_corrected, user_days_corrected = calculate_user_metrics(filter_and_sort_data('datapao_homework_2023.csv'))\n",
    "# \n",
    "# # Recalculate average time per day and rank\n",
    "# user_avg_time_corrected, user_rank_corrected = calculate_avg_time_and_rank(user_time_corrected, user_days_corrected)\n",
    "# \n",
    "# # Create the output for the first part of the exercise\n",
    "# output_first_corrected = [\n",
    "#     [user, user_time_corrected[user], len(user_days_corrected[user]), user_avg_time_corrected[user], user_rank_corrected[user]]\n",
    "#     for user in user_time_corrected\n",
    "# ]\n",
    "# \n",
    "# # Sort by rank to show top 5\n",
    "# output_first_corrected.sort(key=lambda x: x[4])\n",
    "\n",
    "# Call the main function to execute the first task and write the results to a CSV file\n",
    "task_one_main('datapao_homework_2023.csv', 'first.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:54:15.033751900Z",
     "start_time": "2023-10-07T16:54:15.023638900Z"
    }
   },
   "id": "681e5b8eb914e710"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Tests for Task 1\n",
    "\n",
    "class TestTaskOne(unittest.TestCase):\n",
    "\n",
    "    # Sample data for testing\n",
    "    sample_data = [\n",
    "        ('user_1', 'GATE_IN', datetime(2023, 2, 1, 8, 0, 0)),\n",
    "        ('user_1', 'GATE_OUT', datetime(2023, 2, 1, 12, 0, 0)),\n",
    "        ('user_1', 'GATE_IN', datetime(2023, 2, 1, 13, 0, 0)),\n",
    "        ('user_1', 'GATE_OUT', datetime(2023, 2, 1, 18, 0, 0)),\n",
    "        ('user_2', 'GATE_IN', datetime(2023, 2, 1, 9, 0, 0)),\n",
    "        ('user_2', 'GATE_OUT', datetime(2023, 2, 1, 17, 0, 0))\n",
    "    ]\n",
    "\n",
    "    def test_filter_and_sort_data(self):\n",
    "        self.assertEqual(filter_and_sort_data(self.sample_data), self.sample_data)\n",
    "\n",
    "    def test_calculate_user_metrics(self):\n",
    "        user_time, user_days = calculate_user_metrics(self.sample_data)\n",
    "        self.assertEqual(user_time['user_1'], 9.0)  # Changed\n",
    "        self.assertEqual(user_time['user_2'], 8.0)  # Changed\n",
    "        self.assertEqual(len(user_days['user_1']), 1)\n",
    "        self.assertEqual(len(user_days['user_2']), 1)\n",
    "\n",
    "    def test_calculate_avg_time_and_rank(self):\n",
    "        user_time = {'user_1': 9.0, 'user_2': 8.0}  # Changed\n",
    "        user_days = {'user_1': {datetime(2023, 2, 1).date()}, 'user_2': {datetime(2023, 2, 1).date()}}\n",
    "        user_avg_time, user_rank = calculate_avg_time_and_rank(user_time, user_days)\n",
    "        self.assertEqual(user_avg_time['user_1'], 9.0)\n",
    "        self.assertEqual(user_avg_time['user_2'], 8.0)\n",
    "        self.assertEqual(user_rank['user_1'], 1)\n",
    "        self.assertEqual(user_rank['user_2'], 2)\n",
    "\n",
    "# Run the unit tests\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestTaskOne))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:57:40.550282900Z",
     "start_time": "2023-10-07T16:57:40.535532300Z"
    }
   },
   "id": "43ecb3ff833e0bfa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Find out who had the longest work session in February. Write the result to a CSV in the format (user_id, session_length)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8debefeab5303e0"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/second.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_user_sessions(feb_data: List[Tuple[str, str, datetime]]) -> Dict[str, List[Tuple[datetime, datetime]]]:\n",
    "    \"\"\"Calculate metrics like time spent, unique days, and sessions for each user.\"\"\"\n",
    "    user_sessions = defaultdict(list)\n",
    "\n",
    "    for i in range(len(feb_data) - 1):\n",
    "        user_id, event_type, event_time = feb_data[i]\n",
    "        next_user_id, next_event_type, next_event_time = feb_data[i + 1]\n",
    "\n",
    "        if user_id == next_user_id and event_type == \"GATE_IN\" and next_event_type == \"GATE_OUT\":\n",
    "            if user_sessions[user_id]:\n",
    "                last_session_end = user_sessions[user_id][-1][1]\n",
    "                if (event_time - last_session_end).seconds // 3600 >= 2:\n",
    "                    user_sessions[user_id].append((event_time, next_event_time))\n",
    "                else:\n",
    "                    user_sessions[user_id][-1] = (user_sessions[user_id][-1][0], next_event_time)\n",
    "            else:\n",
    "                user_sessions[user_id].append((event_time, next_event_time))\n",
    "\n",
    "    return user_sessions\n",
    "\n",
    "def calculate_longest_session(user_sessions: Dict[str, List[Tuple[datetime, datetime]]]) -> Dict[str, timedelta]:\n",
    "    \"\"\"Calculate the longest work session for each user.\"\"\"\n",
    "    return {user: max((session[1] - session[0] for session in sessions), default=timedelta(0))\n",
    "            for user, sessions in user_sessions.items()}\n",
    "\n",
    "def task_two_main(file_path: str, output_file_path: str) -> None:\n",
    "    \"\"\"Main function to execute Task 2: Calculate and write the longest work sessions to a CSV.\"\"\"\n",
    "    feb_data = filter_and_sort_data(file_path)\n",
    "    user_sessions = calculate_user_sessions(feb_data)\n",
    "\n",
    "    user_longest_session = calculate_longest_session(user_sessions)\n",
    "    sorted_users_by_session = sorted(user_longest_session.items(), key=lambda x: x[1], reverse=True)\n",
    "    output_second = [[user, longest_session.seconds // 3600] for user, longest_session in sorted_users_by_session]\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_directory = 'output/'\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "\n",
    "    # Define the complete output file path\n",
    "    complete_output_file_path = os.path.join(output_directory, output_file_path)\n",
    "    print(complete_output_file_path)\n",
    "\n",
    "    # Write the data to a CSV file\n",
    "    write_to_csv(output_second, ['user_id', 'session_length'], complete_output_file_path)\n",
    "\n",
    "# Define output file path for Task 2\n",
    "output_file_path_2 = 'second.csv'\n",
    "\n",
    "# Call the main function for Task 2\n",
    "task_two_main('datapao_homework_2023.csv', output_file_path_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:11:35.530601100Z",
     "start_time": "2023-10-07T17:11:35.509756200Z"
    }
   },
   "id": "be61ade9eb841470"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Tests for Task 2\n",
    "\n",
    "class TestTaskTwo(unittest.TestCase):\n",
    "\n",
    "    # Sample session data for testing\n",
    "    sample_sessions = {\n",
    "        'user_1': [\n",
    "            (datetime(2023, 2, 1, 8, 0, 0), datetime(2023, 2, 1, 18, 0, 0)),  # Merged session\n",
    "        ],\n",
    "        'user_2': [\n",
    "            (datetime(2023, 2, 1, 9, 0, 0), datetime(2023, 2, 1, 17, 0, 0))\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def test_calculate_longest_session(self):\n",
    "        longest_sessions = calculate_longest_session(self.sample_sessions)\n",
    "        self.assertEqual(longest_sessions['user_1'].seconds // 3600, 10)\n",
    "        self.assertEqual(longest_sessions['user_2'].seconds // 3600, 8)\n",
    "\n",
    "# Run the unit tests for Task 2\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestTaskTwo))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:12:37.422225400Z",
     "start_time": "2023-10-07T17:12:37.416243900Z"
    }
   },
   "id": "b38e265f482a7563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 Identify core working hours -- when are the most employees present?\n",
    "\n",
    "This should help us best book face-to-face meetings and collaborative work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a274551430d4b27b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: -1,\n 1: -2,\n 2: -3,\n 3: -3,\n 4: -3,\n 5: -3,\n 6: -3,\n 7: -3,\n 8: 57,\n 9: 131,\n 10: 153,\n 11: 189,\n 12: 176,\n 13: 180,\n 14: 175,\n 15: 179,\n 16: 174,\n 17: 173,\n 18: 163,\n 19: 137,\n 20: 56,\n 21: -3,\n 22: -2,\n 23: 0}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_hourly_presence(feb_data: List[Tuple[str, str, datetime]]) -> Dict[int, int]:\n",
    "    \"\"\"Calculate the hourly presence of employees.\"\"\"\n",
    "    hourly_presence = Counter()\n",
    "    for user_id, event_type, event_time in feb_data:\n",
    "        if event_type == \"GATE_IN\":\n",
    "            hourly_presence[event_time.hour] += 1\n",
    "        elif event_type == \"GATE_OUT\":\n",
    "            hourly_presence[event_time.hour] -= 1\n",
    "    return hourly_presence\n",
    "\n",
    "def calculate_cumulative_hourly_presence(hourly_presence: Dict[int, int]) -> Dict[int, int]:\n",
    "    \"\"\"Calculate the cumulative hourly presence of employees.\"\"\"\n",
    "    cumulative_presence = 0\n",
    "    hourly_cumulative_presence = {}\n",
    "    for hour in range(24):\n",
    "        cumulative_presence += hourly_presence.get(hour, 0)\n",
    "        hourly_cumulative_presence[hour] = cumulative_presence\n",
    "    return hourly_cumulative_presence\n",
    "\n",
    "# Run the functions for calculating core working hours\n",
    "hourly_presence = calculate_hourly_presence(filter_and_sort_data('datapao_homework_2023.csv'))\n",
    "hourly_cumulative_presence = calculate_cumulative_hourly_presence(hourly_presence)\n",
    "hourly_cumulative_presence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:13:17.890072600Z",
     "start_time": "2023-10-07T17:13:17.877690400Z"
    }
   },
   "id": "152248a84d3528e"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Tests for Core Working Hours Calculation\n",
    "\n",
    "class TestCoreWorkingHours(unittest.TestCase):\n",
    "\n",
    "    # Sample data for testing\n",
    "    sample_data = [\n",
    "        ('user_1', 'GATE_IN', datetime(2023, 2, 1, 8, 0, 0)),\n",
    "        ('user_1', 'GATE_OUT', datetime(2023, 2, 1, 12, 0, 0)),\n",
    "        ('user_1', 'GATE_IN', datetime(2023, 2, 1, 13, 0, 0)),\n",
    "        ('user_1', 'GATE_OUT', datetime(2023, 2, 1, 18, 0, 0)),\n",
    "        ('user_2', 'GATE_IN', datetime(2023, 2, 1, 9, 0, 0)),\n",
    "        ('user_2', 'GATE_OUT', datetime(2023, 2, 1, 17, 0, 0))\n",
    "    ]\n",
    "\n",
    "    def test_calculate_hourly_presence(self):\n",
    "        hourly_presence = calculate_hourly_presence(self.sample_data)\n",
    "        self.assertEqual(hourly_presence[8], 1)\n",
    "        self.assertEqual(hourly_presence[9], 1)\n",
    "        self.assertEqual(hourly_presence[12], -1)\n",
    "        self.assertEqual(hourly_presence[13], 1)\n",
    "        self.assertEqual(hourly_presence[17], -1)\n",
    "        self.assertEqual(hourly_presence[18], -1)\n",
    "\n",
    "    def test_calculate_cumulative_hourly_presence(self):\n",
    "        hourly_presence = calculate_hourly_presence(self.sample_data)\n",
    "        hourly_cumulative_presence = calculate_cumulative_hourly_presence(hourly_presence)\n",
    "        self.assertEqual(hourly_cumulative_presence[8], 1)\n",
    "        self.assertEqual(hourly_cumulative_presence[9], 2)\n",
    "        self.assertEqual(hourly_cumulative_presence[12], 1)\n",
    "        self.assertEqual(hourly_cumulative_presence[13], 2)\n",
    "        self.assertEqual(hourly_cumulative_presence[17], 1)\n",
    "        self.assertEqual(hourly_cumulative_presence[18], 0)\n",
    "\n",
    "# Run the unit tests for Core Working Hours Calculation\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestCoreWorkingHours))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:13:19.779377Z",
     "start_time": "2023-10-07T17:13:19.725948700Z"
    }
   },
   "id": "e49f9a2a93cb2532"
  },
  {
   "cell_type": "markdown",
   "source": [
    "At 11 AM we have the highest employee presence, and it might be best to book larger meetings around that time.\n",
    "\n",
    "The number of people present remains somewhat constant for multiple hours after that, so these hours might be best for any collaborative work sessions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e085b22387db376"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 Flexibility index\n",
    "\n",
    "Calculate the variance in the start and end times of each employee's work sessions. A higher variance indicates the employee has a very flexible schedule, and a lower variance indicates the employee has a strict pattern and routine."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f4a48c812251293"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most flexible workers might be our first people to call when urgent things pop up outside more typical working hours.\n",
    "The least flexible users are predictable, and their schedules might be the easiest to plan around and assign tasks based on."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d7f3f92d831c349"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "([('1fcdd2f5-13ed-4ee8-b4ec-706654e68472', 57.82213438735178),\n  ('bfa0f1f9-300e-41ad-bcff-0c3bd79595f1', 40.01307189542484),\n  ('5dafb3b2-22aa-4039-a2f0-3cf711f84177', 33.97011494252874)],\n [('98ea63ee-bba1-4ea5-8ada-1d0a2dd1f6fd', 23.04),\n  ('oab91046-1831-436d-a41d-da6ba1b2d385', 22.104761904761904),\n  ('33c08c48-f50a-4c72-a975-f8572d65a8db', 22.026666666666664)])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def populate_start_end_times(user_sessions: Dict[str, List[Tuple[datetime, datetime]]]) -> Tuple[Dict[str, List[int]], Dict[str, List[int]]]:\n",
    "    \"\"\"Populate start and end times for each user's work sessions.\"\"\"\n",
    "    user_start_times = defaultdict(list)\n",
    "    user_end_times = defaultdict(list)\n",
    "    for user, sessions in user_sessions.items():\n",
    "        for session_start, session_end in sessions:\n",
    "            user_start_times[user].append(session_start.hour)\n",
    "            user_end_times[user].append(session_end.hour)\n",
    "    return user_start_times, user_end_times\n",
    "\n",
    "def calculate_flexibility_index(user_start_times: Dict[str, List[int]], user_end_times: Dict[str, List[int]]) -> Dict[str, float]:\n",
    "    \"\"\"Calculate the flexibility index for each user.\"\"\"\n",
    "    user_flexibility_index = {}\n",
    "    for user in user_start_times:\n",
    "        start_var = variance(user_start_times[user]) if len(user_start_times[user]) > 1 else 0\n",
    "        end_var = variance(user_end_times[user]) if len(user_end_times[user]) > 1 else 0\n",
    "        user_flexibility_index[user] = start_var + end_var\n",
    "    return user_flexibility_index\n",
    "\n",
    "# Run the functions for calculating flexibility index\n",
    "user_start_times, user_end_times = populate_start_end_times(calculate_user_sessions(filter_and_sort_data('datapao_homework_2023.csv')))\n",
    "user_flexibility_index = calculate_flexibility_index(user_start_times, user_end_times)\n",
    "\n",
    "# Sort the users by Flexibility Index\n",
    "sorted_users_by_flexibility = sorted(user_flexibility_index.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 3 most flexible and least flexible users\n",
    "top_3_most_flexible_users = sorted_users_by_flexibility[:3]\n",
    "top_3_least_flexible_users = sorted_users_by_flexibility[-3:]\n",
    "\n",
    "top_3_most_flexible_users, top_3_least_flexible_users"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:14:15.309094100Z",
     "start_time": "2023-10-07T17:14:15.293731400Z"
    }
   },
   "id": "8f78d706142d9d33"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.001s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit Tests for Flexibility Index Calculation\n",
    "\n",
    "class TestFlexibilityIndex(unittest.TestCase):\n",
    "\n",
    "    # Sample session data for testing\n",
    "    sample_sessions = {\n",
    "        'user_1': [\n",
    "            (datetime(2023, 2, 1, 8, 0, 0), datetime(2023, 2, 1, 18, 0, 0)),  # Merged session\n",
    "            (datetime(2023, 2, 2, 9, 0, 0), datetime(2023, 2, 2, 17, 0, 0))\n",
    "        ],\n",
    "        'user_2': [\n",
    "            (datetime(2023, 2, 1, 9, 0, 0), datetime(2023, 2, 1, 17, 0, 0)),\n",
    "            (datetime(2023, 2, 2, 10, 0, 0), datetime(2023, 2, 2, 16, 0, 0))\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    def test_populate_start_end_times(self):\n",
    "        start_times, end_times = populate_start_end_times(self.sample_sessions)\n",
    "        self.assertEqual(start_times['user_1'], [8, 9])\n",
    "        self.assertEqual(end_times['user_1'], [18, 17])\n",
    "        self.assertEqual(start_times['user_2'], [9, 10])\n",
    "        self.assertEqual(end_times['user_2'], [17, 16])\n",
    "\n",
    "    def test_calculate_flexibility_index(self):\n",
    "        start_times, end_times = populate_start_end_times(self.sample_sessions)\n",
    "        flexibility_index = calculate_flexibility_index(start_times, end_times)\n",
    "        self.assertEqual(flexibility_index['user_1'], 0.5 + 0.5)\n",
    "        self.assertEqual(flexibility_index['user_2'], 0.5 + 0.5)\n",
    "\n",
    "# Run the unit tests for Flexibility Index Calculation\n",
    "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestFlexibilityIndex))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T17:14:20.242123600Z",
     "start_time": "2023-10-07T17:14:20.231235100Z"
    }
   },
   "id": "f52dc93d1558b6c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solving the task with pandas to get a \"correct\" solution for debugging purposes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30a7fd25ff75135a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "                                user_id event_type                event_time\n0  2e5d8815-4e59-4302-99c0-6fc9593a2eef    GATE_IN  2023-01-31T08:18:36.000Z\n1  a8c60645-aef4-4b4e-aefb-65e242536c2f    GATE_IN  2023-01-31T08:43:41.000Z\n2  0b99d382-ea52-4a1d-8e9e-218933c0d7b8    gate_in  2023-01-31T08:43:47.000Z\n3  d22c03ba-00f7-4473-bc9d-61136643994f    GATE_IN  2023-01-31T09:04:08.000Z\n4  1fcdd2f5-13ed-4ee8-b4ec-706654e68472    GATE_IN  2023-01-31T09:12:56.000Z",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>event_type</th>\n      <th>event_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2e5d8815-4e59-4302-99c0-6fc9593a2eef</td>\n      <td>GATE_IN</td>\n      <td>2023-01-31T08:18:36.000Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a8c60645-aef4-4b4e-aefb-65e242536c2f</td>\n      <td>GATE_IN</td>\n      <td>2023-01-31T08:43:41.000Z</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>gate_in</td>\n      <td>2023-01-31T08:43:47.000Z</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d22c03ba-00f7-4473-bc9d-61136643994f</td>\n      <td>GATE_IN</td>\n      <td>2023-01-31T09:04:08.000Z</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1fcdd2f5-13ed-4ee8-b4ec-706654e68472</td>\n      <td>GATE_IN</td>\n      <td>2023-01-31T09:12:56.000Z</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datapao_homework_2023.csv')\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T15:59:57.954133Z",
     "start_time": "2023-10-07T15:59:57.193734400Z"
    }
   },
   "id": "191990ab4d021bb5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  user_id event_type                event_time\n98   0b99d382-ea52-4a1d-8e9e-218933c0d7b8    GATE_IN 2023-02-01 08:29:47+00:00\n120  0b99d382-ea52-4a1d-8e9e-218933c0d7b8   GATE_OUT 2023-02-01 11:49:51+00:00\n132  0b99d382-ea52-4a1d-8e9e-218933c0d7b8    GATE_IN 2023-02-01 13:22:48+00:00\n144  0b99d382-ea52-4a1d-8e9e-218933c0d7b8   GATE_OUT 2023-02-01 14:36:19+00:00\n168  0b99d382-ea52-4a1d-8e9e-218933c0d7b8    GATE_IN 2023-02-01 18:27:42+00:00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>event_type</th>\n      <th>event_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>98</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>GATE_IN</td>\n      <td>2023-02-01 08:29:47+00:00</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>GATE_OUT</td>\n      <td>2023-02-01 11:49:51+00:00</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>GATE_IN</td>\n      <td>2023-02-01 13:22:48+00:00</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>GATE_OUT</td>\n      <td>2023-02-01 14:36:19+00:00</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>GATE_IN</td>\n      <td>2023-02-01 18:27:42+00:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "df['event_type'] = df['event_type'].str.upper()\n",
    "\n",
    "df_feb = df[(df['event_time'].dt.month == 2) & (df['event_time'].dt.year == 2023)]\n",
    "\n",
    "df_feb = df_feb.sort_values(by=['user_id', 'event_time'])\n",
    "\n",
    "df_feb.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:00:01.528960Z",
     "start_time": "2023-10-07T16:00:01.494315400Z"
    }
   },
   "id": "d85240d35bf23ded"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id        time  days  average_per_day  \\\n20  d22c03ba-00f7-4473-bc9d-61136643994f   71.219722    11         6.474520   \n16  a8c60645-aef4-4b4e-aefb-65e242536c2f  107.857500    17         6.344559   \n24  tc83470b-61c3-48c5-9bf3-9d623942e2ec   95.784722    16         5.986545   \n17  abce78a1-f8e6-4e9b-aafe-9786846e089e   79.129444    14         5.652103   \n23  p3b4e81f-79de-4937-ba87-aec8e7e731af  105.220833    19         5.537939   \n15  a59f9f64-2937-40e6-bc28-e43fbab63a65   75.745278    14         5.410377   \n22  oab91046-1831-436d-a41d-da6ba1b2d385   59.390278    11         5.399116   \n4   2c4c1aa0-5dd6-4fc1-b474-6c2ed92dd43c   96.889444    18         5.382747   \n0   0b99d382-ea52-4a1d-8e9e-218933c0d7b8   89.756667    17         5.279804   \n5   2e5d8815-4e59-4302-99c0-6fc9593a2eef   82.947778    16         5.184236   \n7   36ca1a7a-a927-4838-bb36-4fcd974014c9   77.548333    15         5.169889   \n18  b12841ab-ad59-42bc-ad7c-8e9c97cb8fba   96.038333    19         5.054649   \n2   1f55d290-49ff-4512-b1c1-ee92ec9680ab   79.146389    16         4.946649   \n6   33c08c48-f50a-4c72-a975-f8572d65a8db   74.900278    16         4.681267   \n19  bfa0f1f9-300e-41ad-bcff-0c3bd79595f1   60.734722    13         4.671902   \n11  67e4c352-bda1-4289-b0a4-0e25f67af5f2   92.618333    20         4.630917   \n21  f85a9fe3-1744-4181-b81c-a8f93df57f02   77.390833    17         4.552402   \n14  98ea63ee-bba1-4ea5-8ada-1d0a2dd1f6fd   68.257222    15         4.550481   \n10  5dafb3b2-22aa-4039-a2f0-3cf711f84177   86.315556    19         4.542924   \n8   45887b17-5c63-410d-9ae3-e645743c3076   76.908333    17         4.524020   \n1   0e581334-ccca-4141-9731-ddf544b1c549   62.417222    14         4.458373   \n13  8ee31b32-9b50-47da-8927-801a62348cb5   79.629722    18         4.423873   \n9   495958c6-3d03-43e3-b324-b3191d5c78f1   79.077222    18         4.393179   \n12  6ecc43f1-87f4-4a10-b9b9-4447a5d0bc22   63.319444    15         4.221296   \n3   1fcdd2f5-13ed-4ee8-b4ec-706654e68472   55.627778    15         3.708519   \n\n    rank  \n20     1  \n16     2  \n24     3  \n17     4  \n23     5  \n15     6  \n22     7  \n4      8  \n0      9  \n5     10  \n7     11  \n18    12  \n2     13  \n6     14  \n19    15  \n11    16  \n21    17  \n14    18  \n10    19  \n8     20  \n1     21  \n13    22  \n9     23  \n12    24  \n3     25  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>time</th>\n      <th>days</th>\n      <th>average_per_day</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>d22c03ba-00f7-4473-bc9d-61136643994f</td>\n      <td>71.219722</td>\n      <td>11</td>\n      <td>6.474520</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>a8c60645-aef4-4b4e-aefb-65e242536c2f</td>\n      <td>107.857500</td>\n      <td>17</td>\n      <td>6.344559</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>tc83470b-61c3-48c5-9bf3-9d623942e2ec</td>\n      <td>95.784722</td>\n      <td>16</td>\n      <td>5.986545</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>abce78a1-f8e6-4e9b-aafe-9786846e089e</td>\n      <td>79.129444</td>\n      <td>14</td>\n      <td>5.652103</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>p3b4e81f-79de-4937-ba87-aec8e7e731af</td>\n      <td>105.220833</td>\n      <td>19</td>\n      <td>5.537939</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>a59f9f64-2937-40e6-bc28-e43fbab63a65</td>\n      <td>75.745278</td>\n      <td>14</td>\n      <td>5.410377</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>oab91046-1831-436d-a41d-da6ba1b2d385</td>\n      <td>59.390278</td>\n      <td>11</td>\n      <td>5.399116</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2c4c1aa0-5dd6-4fc1-b474-6c2ed92dd43c</td>\n      <td>96.889444</td>\n      <td>18</td>\n      <td>5.382747</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>89.756667</td>\n      <td>17</td>\n      <td>5.279804</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2e5d8815-4e59-4302-99c0-6fc9593a2eef</td>\n      <td>82.947778</td>\n      <td>16</td>\n      <td>5.184236</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>36ca1a7a-a927-4838-bb36-4fcd974014c9</td>\n      <td>77.548333</td>\n      <td>15</td>\n      <td>5.169889</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>b12841ab-ad59-42bc-ad7c-8e9c97cb8fba</td>\n      <td>96.038333</td>\n      <td>19</td>\n      <td>5.054649</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1f55d290-49ff-4512-b1c1-ee92ec9680ab</td>\n      <td>79.146389</td>\n      <td>16</td>\n      <td>4.946649</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>33c08c48-f50a-4c72-a975-f8572d65a8db</td>\n      <td>74.900278</td>\n      <td>16</td>\n      <td>4.681267</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>bfa0f1f9-300e-41ad-bcff-0c3bd79595f1</td>\n      <td>60.734722</td>\n      <td>13</td>\n      <td>4.671902</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>67e4c352-bda1-4289-b0a4-0e25f67af5f2</td>\n      <td>92.618333</td>\n      <td>20</td>\n      <td>4.630917</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>f85a9fe3-1744-4181-b81c-a8f93df57f02</td>\n      <td>77.390833</td>\n      <td>17</td>\n      <td>4.552402</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>98ea63ee-bba1-4ea5-8ada-1d0a2dd1f6fd</td>\n      <td>68.257222</td>\n      <td>15</td>\n      <td>4.550481</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5dafb3b2-22aa-4039-a2f0-3cf711f84177</td>\n      <td>86.315556</td>\n      <td>19</td>\n      <td>4.542924</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>45887b17-5c63-410d-9ae3-e645743c3076</td>\n      <td>76.908333</td>\n      <td>17</td>\n      <td>4.524020</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0e581334-ccca-4141-9731-ddf544b1c549</td>\n      <td>62.417222</td>\n      <td>14</td>\n      <td>4.458373</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>8ee31b32-9b50-47da-8927-801a62348cb5</td>\n      <td>79.629722</td>\n      <td>18</td>\n      <td>4.423873</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>495958c6-3d03-43e3-b324-b3191d5c78f1</td>\n      <td>79.077222</td>\n      <td>18</td>\n      <td>4.393179</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>6ecc43f1-87f4-4a10-b9b9-4447a5d0bc22</td>\n      <td>63.319444</td>\n      <td>15</td>\n      <td>4.221296</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1fcdd2f5-13ed-4ee8-b4ec-706654e68472</td>\n      <td>55.627778</td>\n      <td>15</td>\n      <td>3.708519</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "dfs_to_concat = []\n",
    "\n",
    "# Group by user and then iterate over each group to calculate time spent in the office, number of days, and average time per day\n",
    "for user, user_data in df_feb.groupby('user_id'):\n",
    "    user_data = user_data.sort_values('event_time')\n",
    "    time_spent = 0\n",
    "    days = set()\n",
    "    last_gate_in = None\n",
    "\n",
    "    for i, row in user_data.iterrows():\n",
    "        if row['event_type'] == 'GATE_IN':\n",
    "            last_gate_in = row['event_time']\n",
    "        elif row['event_type'] == 'GATE_OUT' and last_gate_in is not None:\n",
    "            time_spent += (row['event_time'] - last_gate_in).seconds / 3600  # Convert to hours\n",
    "            last_gate_in = None  # Reset for the next pair\n",
    "\n",
    "        days.add(row['event_time'].date())\n",
    "\n",
    "    avg_time_per_day = time_spent / len(days)\n",
    "\n",
    "    # Create a DataFrame for this user and add to the list\n",
    "    user_df = pd.DataFrame({\n",
    "        'user_id': [user],\n",
    "        'time': [time_spent],\n",
    "        'days': [len(days)],\n",
    "        'average_per_day': [avg_time_per_day]\n",
    "    })\n",
    "    dfs_to_concat.append(user_df)\n",
    "\n",
    "# Use `pd.concat` to concatenate all the individual DataFrames\n",
    "results = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "\n",
    "# Calculate the rank based on average_per_day\n",
    "results['rank'] = results['average_per_day'].rank(method='min').astype(int)\n",
    "\n",
    "# Sort the DataFrame by 'average_per_day' in descending order and then calculate the rank\n",
    "results = results.sort_values(by='average_per_day', ascending=False)\n",
    "results['rank'] = results['average_per_day'].rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "# Display the corrected DataFrame sorted by the new rank\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:13:56.856244700Z",
     "start_time": "2023-10-07T16:13:56.803125700Z"
    }
   },
   "id": "7a31b1239249b40c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id  session_length\n23  p3b4e81f-79de-4937-ba87-aec8e7e731af       12.770556\n6   33c08c48-f50a-4c72-a975-f8572d65a8db       12.768611\n24  tc83470b-61c3-48c5-9bf3-9d623942e2ec       12.705556\n16  a8c60645-aef4-4b4e-aefb-65e242536c2f       12.430278\n10  5dafb3b2-22aa-4039-a2f0-3cf711f84177       12.067500\n8   45887b17-5c63-410d-9ae3-e645743c3076       12.003611\n4   2c4c1aa0-5dd6-4fc1-b474-6c2ed92dd43c       11.358333\n5   2e5d8815-4e59-4302-99c0-6fc9593a2eef       11.329722\n13  8ee31b32-9b50-47da-8927-801a62348cb5       10.999444\n0   0b99d382-ea52-4a1d-8e9e-218933c0d7b8       10.961111\n3   1fcdd2f5-13ed-4ee8-b4ec-706654e68472       10.883333\n7   36ca1a7a-a927-4838-bb36-4fcd974014c9       10.738056\n22  oab91046-1831-436d-a41d-da6ba1b2d385       10.689722\n17  abce78a1-f8e6-4e9b-aafe-9786846e089e       10.540833\n21  f85a9fe3-1744-4181-b81c-a8f93df57f02       10.524444\n2   1f55d290-49ff-4512-b1c1-ee92ec9680ab       10.327500\n9   495958c6-3d03-43e3-b324-b3191d5c78f1       10.148889\n15  a59f9f64-2937-40e6-bc28-e43fbab63a65       10.006389\n19  bfa0f1f9-300e-41ad-bcff-0c3bd79595f1        9.590278\n12  6ecc43f1-87f4-4a10-b9b9-4447a5d0bc22        9.521667\n20  d22c03ba-00f7-4473-bc9d-61136643994f        8.828611\n11  67e4c352-bda1-4289-b0a4-0e25f67af5f2        8.743333\n18  b12841ab-ad59-42bc-ad7c-8e9c97cb8fba        8.286389\n14  98ea63ee-bba1-4ea5-8ada-1d0a2dd1f6fd        8.243889\n1   0e581334-ccca-4141-9731-ddf544b1c549        8.018333",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>session_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>p3b4e81f-79de-4937-ba87-aec8e7e731af</td>\n      <td>12.770556</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>33c08c48-f50a-4c72-a975-f8572d65a8db</td>\n      <td>12.768611</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>tc83470b-61c3-48c5-9bf3-9d623942e2ec</td>\n      <td>12.705556</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>a8c60645-aef4-4b4e-aefb-65e242536c2f</td>\n      <td>12.430278</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5dafb3b2-22aa-4039-a2f0-3cf711f84177</td>\n      <td>12.067500</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>45887b17-5c63-410d-9ae3-e645743c3076</td>\n      <td>12.003611</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2c4c1aa0-5dd6-4fc1-b474-6c2ed92dd43c</td>\n      <td>11.358333</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2e5d8815-4e59-4302-99c0-6fc9593a2eef</td>\n      <td>11.329722</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>8ee31b32-9b50-47da-8927-801a62348cb5</td>\n      <td>10.999444</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0b99d382-ea52-4a1d-8e9e-218933c0d7b8</td>\n      <td>10.961111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1fcdd2f5-13ed-4ee8-b4ec-706654e68472</td>\n      <td>10.883333</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>36ca1a7a-a927-4838-bb36-4fcd974014c9</td>\n      <td>10.738056</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>oab91046-1831-436d-a41d-da6ba1b2d385</td>\n      <td>10.689722</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>abce78a1-f8e6-4e9b-aafe-9786846e089e</td>\n      <td>10.540833</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>f85a9fe3-1744-4181-b81c-a8f93df57f02</td>\n      <td>10.524444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1f55d290-49ff-4512-b1c1-ee92ec9680ab</td>\n      <td>10.327500</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>495958c6-3d03-43e3-b324-b3191d5c78f1</td>\n      <td>10.148889</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>a59f9f64-2937-40e6-bc28-e43fbab63a65</td>\n      <td>10.006389</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>bfa0f1f9-300e-41ad-bcff-0c3bd79595f1</td>\n      <td>9.590278</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>6ecc43f1-87f4-4a10-b9b9-4447a5d0bc22</td>\n      <td>9.521667</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>d22c03ba-00f7-4473-bc9d-61136643994f</td>\n      <td>8.828611</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>67e4c352-bda1-4289-b0a4-0e25f67af5f2</td>\n      <td>8.743333</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>b12841ab-ad59-42bc-ad7c-8e9c97cb8fba</td>\n      <td>8.286389</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>98ea63ee-bba1-4ea5-8ada-1d0a2dd1f6fd</td>\n      <td>8.243889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0e581334-ccca-4141-9731-ddf544b1c549</td>\n      <td>8.018333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To calculate the longest work session, we'll consider a gap of two or more hours between an 'OUT' and the next 'IN' as the end of a session.\n",
    "# We'll group the data by user, then iterate over each user's data to identify sessions and their lengths.\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "longest_sessions = []\n",
    "\n",
    "# Define the threshold for a new session in hours\n",
    "threshold = 2\n",
    "\n",
    "# Group by user and then iterate over each group to identify work sessions\n",
    "for user, user_data in df_feb.groupby('user_id'):\n",
    "    user_data = user_data.sort_values('event_time')\n",
    "    longest_session = 0\n",
    "    session_start = None\n",
    "    last_event_time = None\n",
    "    last_event_type = None\n",
    "\n",
    "    for i, row in user_data.iterrows():\n",
    "        if row['event_type'] == 'GATE_IN':\n",
    "            # Check if the gap between the last 'OUT' and this 'IN' is greater than the threshold\n",
    "            if last_event_type == 'GATE_OUT' and (row['event_time'] - last_event_time).seconds / 3600 >= threshold:\n",
    "                # End the current session and start a new one\n",
    "                session_length = (last_event_time - session_start).seconds / 3600  # Convert to hours\n",
    "                longest_session = max(longest_session, session_length)\n",
    "                session_start = row['event_time']\n",
    "            elif session_start is None:\n",
    "                session_start = row['event_time']\n",
    "\n",
    "        elif row['event_type'] == 'GATE_OUT':\n",
    "            if session_start is not None:\n",
    "                session_length = (row['event_time'] - session_start).seconds / 3600  # Convert to hours\n",
    "                longest_session = max(longest_session, session_length)\n",
    "\n",
    "        last_event_time = row['event_time']\n",
    "        last_event_type = row['event_type']\n",
    "\n",
    "    # Append the result to the list\n",
    "    longest_sessions.append({\n",
    "        'user_id': user,\n",
    "        'session_length': longest_session\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df_longest_sessions = pd.DataFrame(longest_sessions)\n",
    "\n",
    "# Sort the DataFrame by session_length in descending order to identify the user with the longest work session\n",
    "df_longest_sessions = df_longest_sessions.sort_values(by='session_length', ascending=False)\n",
    "\n",
    "df_longest_sessions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-07T16:16:04.871858900Z",
     "start_time": "2023-10-07T16:16:04.778399600Z"
    }
   },
   "id": "e193f33629c95cde"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c5878225855dbeb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
